{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e92500df",
      "metadata": {
        "id": "e92500df"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b94775a",
      "metadata": {
        "id": "8b94775a"
      },
      "source": [
        "#### data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "27b8fa78",
      "metadata": {
        "id": "27b8fa78"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/Bank_Personal_Loan_Modelling.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee0b800",
      "metadata": {
        "id": "8ee0b800"
      },
      "source": [
        "#### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "6aa8d55a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "6aa8d55a",
        "outputId": "7be0d473-d369-4853-adbc-6db5bd583cea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a512b761f620>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ZIP Code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Experience\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Experience\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Experience\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4956\u001b[0m         \"\"\"\n\u001b[0;32m-> 4957\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4267\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6661\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['ID', 'ZIP Code'] not found in axis\""
          ]
        }
      ],
      "source": [
        "df.drop([\"ID\", \"ZIP Code\"],axis=1,inplace=True)\n",
        "print(df[\"Experience\"].unique())\n",
        "df[\"Experience\"] = abs(df[\"Experience\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "10481a9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10481a9e",
        "outputId": "8481892d-76cd-41e2-bf95-3fd768f0718f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Education',\n",
              "       'Mortgage', 'Personal Loan', 'Securities Account', 'CD Account',\n",
              "       'Online', 'CreditCard'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c0df4086",
      "metadata": {
        "id": "c0df4086"
      },
      "outputs": [],
      "source": [
        "df = df[['Age', 'Experience', 'Income', 'Family', 'CCAvg','Education', 'Mortgage', 'Securities Account','CD Account', 'Online', 'CreditCard', 'Personal Loan']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0b115140",
      "metadata": {
        "id": "0b115140"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "Y = df.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93f5a7aa",
      "metadata": {
        "id": "93f5a7aa"
      },
      "source": [
        "### Spliting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bcd06381",
      "metadata": {
        "id": "bcd06381"
      },
      "outputs": [],
      "source": [
        "x,y = X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1d8cad0f",
      "metadata": {
        "id": "1d8cad0f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1b7bd982",
      "metadata": {
        "id": "1b7bd982"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "7433f158",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7433f158",
        "outputId": "87e35868-4c59-4f00-a26a-d8e626a62f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3750, 11)\n",
            "X_test shape: (1250, 11)\n",
            "y_train shape: (3750,)\n",
            "y_test shape: (1250,)\n"
          ]
        }
      ],
      "source": [
        "print('X_train shape:', x_train.shape)\n",
        "print('X_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "d1f1c3f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1f1c3f1",
        "outputId": "0e64f897-daaf-448a-dc69-c51ed9a27e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3750, 11]) torch.Size([3750])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.003\n",
        "EPOCH = 50\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_x = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
        "train_y = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        "print(train_x.shape, train_y.shape)\n",
        "\n",
        "dataset = TensorDataset(train_x, train_y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "83535d93",
      "metadata": {
        "id": "83535d93"
      },
      "outputs": [],
      "source": [
        "data = TensorDataset(train_x,train_y)\n",
        "data = DataLoader(data,batch_size=BATCH_SIZE,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d4d0b641",
      "metadata": {
        "id": "d4d0b641"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        \n",
        "        self.layer1 = torch.nn.Linear(11,16)\n",
        "        self.layer2 = torch.nn.Linear(16,1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "4e1e2959",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e1e2959",
        "outputId": "b0318a08-51f8-4b11-a2e8-df07b1b08526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (layer1): Linear(in_features=11, out_features=16, bias=True)\n",
            "  (layer2): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "11760630",
      "metadata": {
        "id": "11760630"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "33818458",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33818458",
        "outputId": "4df2318d-18fc-443f-9ec9-a734bba26da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 0.06562760436584553 0.9784\n",
            "20 0.05356907806197802 0.9808\n",
            "30 0.0465450307349364 0.984\n",
            "40 0.042843871534530384 0.9858666666666667\n",
            "50 0.038280525678147874 0.9882666666666666\n"
          ]
        }
      ],
      "source": [
        "training_loss = [0]*EPOCH\n",
        "training_accuracy = [0]*EPOCH\n",
        "\n",
        "for i in range(1,EPOCH+1):\n",
        "    epoch_loss = 0\n",
        "    accuracy = 0\n",
        "    for x_batch,y_batch in data:\n",
        "        # x_batch,y_batch = x_batch.to(device),y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(x_batch)\n",
        "        \n",
        "        loss = loss_function(y_pred,y_batch.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * len(x_batch)\n",
        "        cnt = (torch.where(y_pred>=0.5, 1, 0) == y_batch.unsqueeze(1)).sum().float()\n",
        "        accuracy += cnt.item()\n",
        "    if(i%10 == 0):\n",
        "        print(i,epoch_loss/len(data.dataset),(accuracy)/len(data.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "136df251",
      "metadata": {
        "id": "136df251"
      },
      "outputs": [],
      "source": [
        "test_x = torch.from_numpy(x_test).to(torch.float32)\n",
        "test_y = torch.from_numpy(y_test).to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a0cc2232",
      "metadata": {
        "id": "a0cc2232"
      },
      "outputs": [],
      "source": [
        "test = TensorDataset(test_x,test_y)\n",
        "test = DataLoader(test,batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "563ce588",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "563ce588",
        "outputId": "38d6f0d9-6ece-4024-e47e-fdad1ae9d601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9824\n"
          ]
        }
      ],
      "source": [
        "y_pred = model(test_x)\n",
        "y_pred = torch.where(y_pred>=0.5, 1, 0).flatten()\n",
        "accuracy = (y_pred == test_y).sum().float().item() / len(test.dataset)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cultural algorithm"
      ],
      "metadata": {
        "id": "RKbXSYQOqSg0"
      },
      "id": "RKbXSYQOqSg0"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('/content/Bank_Personal_Loan_Modelling.csv')\n",
        "\n",
        "X = df.iloc[:, 3:13].values\n",
        "y = df.iloc[:, 13].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_shape=(10,), activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "pop_size = 20\n",
        "max_gen = 50\n",
        "p_c = 0.8\n",
        "p_m = 0.1\n",
        "\n",
        "def fitness(individual):\n",
        "    \n",
        "    model.set_weights(individual)\n",
        "    \n",
        "    model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy')\n",
        "    model.fit(X_train, y_train, batch_size=10, epochs=100)\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = (y_pred > 0.5)\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "def init():\n",
        "    population = []\n",
        "    for i in range(pop_size):\n",
        "        weights = []\n",
        "        for layer in model.layers:\n",
        "            if len(layer.get_weights()) > 0:\n",
        "                w = layer.get_weights()[0]\n",
        "                b = layer.get_weights()[1]\n",
        "                weights.append(w.flatten())\n",
        "                weights.append(b.flatten())\n",
        "        population.append(np.concatenate(weights))\n",
        "    return population\n",
        "\n",
        "def selection(population, fitness_values):\n",
        "    sorted_indices = np.argsort(fitness_values)[::-1]\n",
        "    selected_indices = sorted_indices[:int(pop_size/2)]\n",
        "    return [population[i] for i in selected_indices]\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    child1 = np.zeros_like(parent1)\n",
        "    child2 = np.zeros_like(parent2)\n",
        "    for i in range(len(parent1)):\n",
        "        if np.random.rand() < p_c:\n",
        "            child1[i] = parent2[i]\n",
        "            child2[i] = parent1[i]\n",
        "        else:\n",
        "            child1[i] = parent1[i]\n",
        "            child2[i] = parent2[i]\n",
        "    return child1, child2\n",
        "\n",
        "def mutation(child):\n",
        "    for i in range(len(child)):\n",
        "        if np.random.rand() < p_m:\n",
        "            child[i] += np.random.uniform(-1, 1)\n",
        "    return child\n",
        "\n",
        "def cultural_algorithm():\n",
        "    \n",
        "    population = init()\n",
        "    for gen in range(max_gen):\n",
        "        \n",
        "        fitness_values = [fitness(individual) for individual in population]\n",
        "        \n",
        "        parents = selection(population, fitness_values)\n",
        "        \n",
        "        offspring = []\n",
        "        while len(offspring) < pop_size:\n",
        "            parent1 = np.random.choice(parents)\n",
        "            parent2 = np.random.choice(parents)\n",
        "            child1, child2 = crossover(parent1, parent2)\n",
        "            child1 = mutation(child1)\n",
        "            child2 = mutation(child2)\n",
        "            offspring.append(child1)\n",
        "            offspring.append(child2)\n",
        "        \n",
        "        population = parents + offspring\n",
        "        \n",
        "        population = np.unique(population, axis=0)\n",
        "        population = population[:pop_size]\n",
        "   \n",
        "    fitness_values = [fitness(individual) for individual in population]\n",
        "    \n",
        "    best_index = np.argmax(fitness_values)\n",
        "    best_individual = population[best_index]\n",
        "    model.set_weights(best_individual)\n",
        "    \n",
        "    model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy')\n",
        "    model.fit(X, y, batch_size=10, epochs=100)\n",
        "    accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdtiWzkKqRlj",
        "outputId": "5de851a9-733c-4180-e36c-38a3d7cfda19"
      },
      "id": "FdtiWzkKqRlj",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: [0.9008, 0.0992, 0.1032, 0.9008, 0.1136, 0.9008, 0.0992, 0.8877333333333334, 0.8688, 0.0992]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb00114",
      "metadata": {
        "id": "2eb00114"
      },
      "source": [
        "## Particle Swarm optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('/content/Bank_Personal_Loan_Modelling.csv')\n",
        "\n",
        "X = df.iloc[:, 3:13].values\n",
        "y = df.iloc[:, 13].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_shape=(10,), activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "w_size = sum([w.size for w in model.get_weights()])\n",
        "pop_size = 20\n",
        "max_iter = 50\n",
        "c1 = 1.0\n",
        "c2 = 1.0\n",
        "w = 0.8\n",
        "v_max = 0.5\n",
        "v_min = -0.5\n",
        "\n",
        "def fitness(individual):\n",
        "    \n",
        "    model.set_weights(np.split(individual, w_size))\n",
        "    \n",
        "    model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy')\n",
        "    model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0)\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = (y_pred > 0.5)\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "def init_population():\n",
        "    population = []\n",
        "    for i in range(pop_size):\n",
        "        individual = np.random.uniform(-1, 1, w_size)\n",
        "        population.append(individual)\n",
        "    return population\n",
        "\n",
        "def update_particle(particle, p_best, g_best, v):\n",
        "    r1 = np.random.uniform(0, 1, w_size)\n",
        "    r2 = np.random.uniform(0, 1, w_size)\n",
        "    v = (w * v) + (c1 * r1 * (p_best - particle)) + (c2 * r2 * (g_best - particle))\n",
        "    v = np.clip(v, v_min, v_max)\n",
        "    particle += v\n",
        "    particle = np.clip(particle, -1, 1)\n",
        "    return particle, v\n",
        "\n",
        "def pso():\n",
        "    \n",
        "    population = init_population()\n",
        "    p_best = np.copy(population)\n",
        "    fitness_values = np.array([fitness(individual) for individual in population])\n",
        "    g_best_index = np.argmax(fitness_values)\n",
        "    g_best = np.copy(population[g_best_index])\n",
        "    \n",
        "    for i in range(max_iter):\n",
        "        for j in range(pop_size):\n",
        "            population[j], v = update_particle(population[j], p_best[j], g_best, v=np.zeros(w_size))\n",
        "            p_best_fitness = fitness(p_best[j])\n",
        "            if fitness_values[j] < p_best_fitness:\n",
        "                p_best[j] = population[j]\n",
        "            if p_best_fitness > fitness(g_best):\n",
        "                g_best = p_best[j]\n",
        "        \n",
        "        fitness_values = np.array([fitness(individual) for individual in population])\n",
        "        g_best_index = np.argmax(fitness_values)\n",
        "        g_best = np.copy(population[g_best_index])\n",
        "        print(\"Iteration {}: Best Fitness = {:.4f}\".format(i+1, fitness(g_best)))\n",
        "    \n",
        "    model.set_weights(np.split(g_best, w_size))\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    x = score[1]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg_dBnFYq3Be",
        "outputId": "24159d6d-49b6-4f89-8617-c0df1460e35d"
      },
      "id": "kg_dBnFYq3Be",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25.  1. 49. ...  0.  0.  0.]\n",
            " [45. 19. 34. ...  0.  0.  0.]\n",
            " [39. 15. 11. ...  0.  0.  0.]\n",
            " ...\n",
            " [63. 39. 24. ...  0.  0.  0.]\n",
            " [65. 40. 49. ...  0.  1.  0.]\n",
            " [28.  4. 83. ...  0.  1.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0801fcc8",
      "metadata": {
        "id": "0801fcc8"
      },
      "source": [
        "## Ant Colony optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "5940808f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5940808f",
        "outputId": "533ed8fb-8b1a-40d2-cae1-9a7f252d04e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff14a9e4d00>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "torch.manual_seed(6699)\n",
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "0ce8f252",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ce8f252",
        "outputId": "2db51bdd-5e75-4861-f5d5-6c2a6c88c4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dim :  209\n",
            "Layers Shape :  [(16, 11), (16,), (1, 16), (1,)]\n",
            "Layers Size :  [176, 16, 16, 1]\n"
          ]
        }
      ],
      "source": [
        "dummy = Model()\n",
        "dummy_param = np.concatenate([i.numpy().flatten() for i in dummy.parameters()])\n",
        "shape = [i.numpy().shape for i in model.parameters()]\n",
        "size = [i[0]*i[1] if len(i) == 2 else i[0] for i in shape]\n",
        "dim = len(dummy_param)\n",
        "\n",
        "print(\"Dim : \", dim)\n",
        "print(\"Layers Shape : \", shape)\n",
        "print(\"Layers Size : \", size)\n",
        "\n",
        "dummy = None\n",
        "dummy_param = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a9c48f45",
      "metadata": {
        "id": "a9c48f45"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def model_to_vector(model):\n",
        "    vector = np.concatenate([i.numpy().flatten() for i in model.parameters()])\n",
        "    return vector\n",
        "    \n",
        "def vector_to_model(vector):\n",
        "    param = list()\n",
        "    cum_sum = 0\n",
        "    for i in range(len(size)):\n",
        "        array = vector[cum_sum : cum_sum + size[i]]\n",
        "        array = array.reshape(shape[i])\n",
        "        cum_sum += size[i]\n",
        "        param.append(array)\n",
        "    param = np.array(param, dtype=\"object\")\n",
        "    \n",
        "    dummy_model = Model()\n",
        "    for idx,wei in enumerate(dummy_model.parameters()):\n",
        "        wei.data = (torch.tensor(param[idx])).to(torch.float32)\n",
        "        \n",
        "    return dummy_model    \n",
        "\n",
        "def calc_accuracy(model):\n",
        "    y_pred = model(train_x)\n",
        "    y_pred = torch.where(y_pred>=0.5, 1, 0).flatten()\n",
        "    acc = (y_pred == train_y).sum().float().item() / len(data.dataset)\n",
        "    \n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "1211355d",
      "metadata": {
        "id": "1211355d"
      },
      "outputs": [],
      "source": [
        "ants = 10\n",
        "loops = 100\n",
        "evaporation_rate = 0.2\n",
        "influence_factor = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "15e268d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15e268d8",
        "outputId": "3cafd122-4497-4eca-825d-f62802db9b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iters 0 : 0.8978666666666667\n",
            "Iters 10 : 0.9008\n",
            "Iters 20 : 0.9008\n",
            "Iters 30 : 0.9008\n",
            "Iters 40 : 0.9008\n",
            "Iters 50 : 0.9008\n",
            "Iters 60 : 0.9008\n",
            "Iters 70 : 0.9008\n",
            "Iters 80 : 0.9008\n",
            "Iters 90 : 0.9008\n"
          ]
        }
      ],
      "source": [
        "pheromones = np.ones(dim)\n",
        "max_accuracy = 0\n",
        "fittest_vector = None\n",
        "\n",
        "for loop in range(loops):\n",
        "    # Generate Solution\n",
        "    paths = np.array([Model() for i in range(ants)])\n",
        "    accuracy = []\n",
        "    \n",
        "    for ant in range(ants):\n",
        "        # Flatten the weights and biases\n",
        "        vector = model_to_vector(paths[ant])\n",
        "        \n",
        "        # Multiply with pheromones \n",
        "        vector = vector * pheromones\n",
        "        \n",
        "        # Calculate Accuracy and Append to the list\n",
        "        model = vector_to_model(vector)\n",
        "        acc = calc_accuracy(model)\n",
        "        accuracy.append(acc)\n",
        "        \n",
        "        # Update the updated path\n",
        "        paths[ant] = model\n",
        "        \n",
        "        # Reset\n",
        "        model = None\n",
        "        acc = None\n",
        "        \n",
        "    # Select fittest path and accuracy\n",
        "    paths = paths[np.argsort(accuracy)]\n",
        "    \n",
        "    if accuracy[np.argmax(accuracy)] > max_accuracy:\n",
        "        max_accuracy = accuracy[np.argmax(accuracy)]\n",
        "        fittest_vector = model_to_vector(paths[-1])\n",
        "    \n",
        "    # Update pheromones\n",
        "    delta = 0\n",
        "    for ant in range(ants):\n",
        "        # Flatten the weights and biases\n",
        "        vector = model_to_vector(paths[ant])\n",
        "        \n",
        "        # Calculate delta\n",
        "        delta += (vector - fittest_vector)*influence_factor\n",
        "        \n",
        "    pheromones = (1-pheromones)*evaporation_rate + delta\n",
        "    \n",
        "    if loop%10 == 0:\n",
        "        print(\"Iters {} :\".format(loop), calc_accuracy(paths[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "062fd946",
      "metadata": {
        "id": "062fd946"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2f9552e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f9552e3",
        "outputId": "6a018322-e2f3-44ea-b2d3-b84ce68d4fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.98      1180\n",
            "           1       0.56      0.86      0.67        70\n",
            "\n",
            "    accuracy                           0.95      1250\n",
            "   macro avg       0.77      0.91      0.82      1250\n",
            "weighted avg       0.97      0.95      0.96      1250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = best_model(test_x)\n",
        "y_pred = torch.where(y_pred>=0.5, 1, 0).flatten()\n",
        "\n",
        "print(classification_report(y_pred,test_y))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}